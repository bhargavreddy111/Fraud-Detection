{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5_ Bhargav.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargavreddy111/Fraud-Detection/blob/master/Customer%20Churn%20Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "colab_type": "code",
        "outputId": "e51e7615-5624-4c92-d82e-129c58754b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#NLTK-------------------------------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "#from nltk.stemporter import PorterStemmer\n",
        "\n",
        "# Import libraries for feature \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "colab_type": "code",
        "outputId": "96ab495e-db78-4077-e039-aa158f66b592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Read files\n",
        "textfile = r'/gdrive/My Drive/Assignment 5/Comments.csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'/gdrive/My Drive/Assignment 5/Customers.csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "colab_type": "code",
        "outputId": "971e1d0e-c48f-4f30-88d1-331e635f00af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Extract target column from Customer Info file\n",
        "y_train = CustInfoData[\"TARGET\"]\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "                     \n",
        "print(X_train.shape)\n",
        "print(textData.shape)\n",
        "textData.head()\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 16)\n",
            "(2070, 2)\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWYNz2Ep17l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
        "\n",
        "export_csv = textData.to_csv(r'/gdrive/My Drive/Assignment 5/TextDataTokenized1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mdmGAFDk7xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Snowball stemmer.\n",
        "stemmer1 = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData1=pd.DataFrame()\n",
        "newTextData1=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData1['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer1.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData1.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData_st1.csv')\n",
        "\n",
        "#Join stemmed strings\n",
        "newTextData1['CommentsTokenizedStemmed'] = newTextData1['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData1.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData-Joined_st1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFFHQFDr9CO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textData.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA3MDSyi3a1v",
        "colab_type": "code",
        "outputId": "bcca4add-8035-4d69-f207-ea4c7deeb750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cv1 = CountVectorizer(lowercase=False)\n",
        "counts1 = cv1.fit_transform(newTextData1.CommentsTokenizedStemmed)\n",
        "print(counts1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 466)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VZJ4tuonFPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Porter stemmer.\n",
        "stemmer2 = PorterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData2=pd.DataFrame()\n",
        "newTextData2=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData2['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer2.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData2.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData_st2.csv')\n",
        "\n",
        "#Join stemmed strings\n",
        "newTextData2['CommentsTokenizedStemmed'] = newTextData2['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData2.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData-Joined_st2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce12ZOak4HKL",
        "colab_type": "code",
        "outputId": "086dac66-1563-4f04-972f-8d3cedceb63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cv2 = CountVectorizer(lowercase=False)\n",
        "counts2 = cv2.fit_transform(newTextData2.CommentsTokenizedStemmed)\n",
        "print(counts2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 474)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tESDKCHnp789",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Lancaster stemmer.\n",
        "stemmer3 = LancasterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData3=pd.DataFrame()\n",
        "newTextData3=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData3['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer3.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData3.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData_st3.csv')\n",
        "\n",
        "#Join stemmed strings\n",
        "newTextData3['CommentsTokenizedStemmed'] = newTextData3['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData3.to_csv(r'/gdrive/My Drive/Assignment 5/newTextData-Joined_st3.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I-K_s5N4Wgs",
        "colab_type": "code",
        "outputId": "cdd63b81-52f3-4164-8366-411489cddba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cv3 = CountVectorizer(lowercase=False)\n",
        "counts3 = cv3.fit_transform(newTextData3.CommentsTokenizedStemmed)\n",
        "print(counts3.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBguQloljam",
        "colab_type": "code",
        "outputId": "33e85071-f4f5-47c7-81cb-3eda9f444bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Do Bag-Of-Words model - Term - Document Matrix\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect1 = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts1 = count_vect1.fit_transform(newTextData1.CommentsTokenizedStemmed)\n",
        "print(TD_counts1.shape)\n",
        "TD_counts1.dtype\n",
        "print(count_vect1.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts1=pd.DataFrame(TD_counts1.toarray())\n",
        "#print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts1.to_csv(r'/gdrive/My Drive/Assignment 5/TD_counts1-TokenizedStemmed.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 354)\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJ-BayJryG7",
        "colab_type": "code",
        "outputId": "73df767a-b2f4-4d70-b07d-42ecbdf03e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Do Bag-Of-Words model - Term - Document Matrix for Porter Stemmer data\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect2 = CountVectorizer(stop_words='english',lowercase=True)\n",
        "TD_counts2 = count_vect2.fit_transform(newTextData2.CommentsTokenizedStemmed)\n",
        "print(TD_counts2.shape)\n",
        "TD_counts2.dtype\n",
        "print(count_vect2.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts2=pd.DataFrame(TD_counts2.toarray())\n",
        "#print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts2.to_csv(r'/gdrive/My Drive/Assignment 5/TD_counts2-TokenizedStemmed.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 358)\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constanli', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exactli', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'ha', 'handset', 'happi', 'hard', 'hardli', 'hate', 'hear', 'heard', 'help', 'hi', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'lo', 'local', 'locat', 'locatn', 'long', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'properli', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'significantli', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'thi', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkzmexgttre8",
        "colab_type": "code",
        "outputId": "6015b45f-7853-495f-bdfd-87dfe2dc311a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Do Bag-Of-Words model - Term - Document Matrix for Lancaster Stemmer data\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect3 = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts3 = count_vect3.fit_transform(newTextData3.CommentsTokenizedStemmed)\n",
        "print(TD_counts3.shape)\n",
        "TD_counts3.dtype\n",
        "print(count_vect3.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts3=pd.DataFrame(TD_counts3.toarray())\n",
        "#print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts3.to_csv(r'/gdrive/My Drive/Assignment 5/TD_counts3-TokenizedStemmed.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 364)\n",
            "['3399', '3g', 'abysm', 'access', 'ad', 'adapt', 'addit', 'additon', 'address', 'adit', 'adress', 'advert', 'afraid', 'aft', 'al', 'alway', 'angel', 'angry', 'anoth', 'anyth', 'anytim', 'ar', 'asap', 'ask', 'bad', 'bas', 'batery', 'battery', 'becaus', 'believ', 'bet', 'big', 'bil', 'book', 'bought', 'brain', 'bring', 'built', 'busy', 'button', 'buy', 'cal', 'cancel', 'car', 'carry', 'caus', 'cc', 'cel', 'certain', 'chang', 'charg', 'check', 'chip', 'city', 'claim', 'clear', 'cold', 'comapr', 'comp', 'company', 'competit', 'complain', 'complaint', 'conceiv', 'connect', 'consisit', 'consist', 'const', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cov', 'cre', 'credit', 'cstmer', 'cstmr', 'cur', 'cust', 'custom', 'customr', 'dat', 'day', 'dead', 'dec', 'defect', 'deo', 'did', 'die', 'diff', 'difficult', 'digit', 'direct', 'dis', 'doe', 'don', 'dont', 'drop', 'dur', 'dying', 'easy', 'effect', 'encount', 'end', 'enemy', 'equip', 'ev', 'everytim', 'everywh', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famy', 'feat', 'fed', 'fig', 'fin', 'fix', 'forev', 'forward', 'friend', 'funct', 'furtherm', 'fut', 'gav', 'giv', 'goat', 'going', 'good', 'gre', 'gsm', 'handset', 'happy', 'hard', 'hat', 'hav', 'hear', 'heard', 'help', 'high', 'highway', 'hochy', 'hol', 'hom', 'hop', 'horr', 'hous', 'impl', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'jun', 'just', 'kid', 'kno', 'know', 'lam', 'lat', 'lctn', 'learn', 'leroy', 'lik', 'lin', 'list', 'loc', 'locatn', 'long', 'los', 'lost', 'lot', 'lov', 'mad', 'maj', 'mak', 'man', 'market', 'mean', 'mess', 'metropolit', 'minut', 'misl', 'mistak', 'model', 'momm', 'mor', 'mov', 'mr', 'napeleon', 'near', 'nearest', 'nee', 'network', 'nev', 'new', 'num', 'numb', 'oft', 'old', 'omer', 'op', 'opt', 'ory', 'ot', 'oth', 'outbound', 'ov', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phon', 'piec', 'plan', 'pleas', 'point', 'policy', 'poor', 'poss', 'prob', 'problem', 'prop', 'provid', 'purpos', 'rat', 'real', 'reason', 'receiv', 'recpt', 'reent', 'refer', 'rel', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'rol', 'rub', 'rud', 'said', 'sal', 'sam', 'say', 'screening', 'self', 'send', 'serv', 'shitty', 'shut', 'sign', 'sim', 'simply', 'sint', 'sit', 'slow', 'sold', 'som', 'someon', 'sometim', 'soon', 'speak', 'spee', 'start', 'stat', 'stil', 'stol', 'stor', 'stuff', 'stupid', 'subst', 'subtract', 'suck', 'suggest', 'superv', 'support', 'sur', 'surpr', 'suspect', 'suspend', 'switch', 'tak', 'teach', 'techn', 'tel', 'terr', 'test', 'text', 'ther', 'thes', 'thi', 'think', 'thos', 'thought', 'ticket', 'til', 'tim', 'tir', 'today', 'toilet', 'told', 'ton', 'tow', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'try', 'turn', 'uncomfort', 'understand', 'unhappy', 'unlimit', 'unrely', 'unwil', 'upset', 'useless', 'valu', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'wel', 'wer', 'wher', 'wheth', 'whol', 'wif', 'wil', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'yo', 'york']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8TZYnAxQbP",
        "colab_type": "code",
        "outputId": "aa07448d-87b2-42fd-c23f-e95d77dc31af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf1 = tfidf_transformer.fit_transform(TD_counts1)\n",
        "print(X_train_tfidf1.shape)\n",
        "DF_TF_IDF1=pd.DataFrame(X_train_tfidf1.toarray())\n",
        "print(DF_TF_IDF1)\n",
        "export_csv= DF_TF_IDF1.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-TokenizedStemmed_1.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 354)\n",
            "      0    1    2    3        4    5    ...  348  349  350  351  352  353\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljrcn8Wp959n",
        "colab_type": "code",
        "outputId": "b4287bf3-02fb-469a-fb87-30fe01d725e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "DF_TF_IDF1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "      <th>334</th>\n",
              "      <th>335</th>\n",
              "      <th>336</th>\n",
              "      <th>337</th>\n",
              "      <th>338</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "      <th>349</th>\n",
              "      <th>350</th>\n",
              "      <th>351</th>\n",
              "      <th>352</th>\n",
              "      <th>353</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.388928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.275333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.480064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.348322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 354 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3        4    5    ...  348  349  350  351  352  353\n",
              "0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0  0.27568  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 354 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOH2jvrvwFNp",
        "colab_type": "code",
        "outputId": "8c3fd913-8672-4007-baaa-3c17be71b09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf2 = tfidf_transformer.fit_transform(TD_counts2)\n",
        "print(X_train_tfidf2.shape)\n",
        "DF_TF_IDF2=pd.DataFrame(X_train_tfidf2.toarray())\n",
        "print(DF_TF_IDF2)\n",
        "export_csv= DF_TF_IDF2.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-TokenizedStemmed_2.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 358)\n",
            "      0    1    2    3        4    5    ...  352  353  354  355  356  357\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 358 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ9za8lSw03o",
        "colab_type": "code",
        "outputId": "33aedffa-da8f-4edb-fc3e-ce147d697b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf3 = tfidf_transformer.fit_transform(TD_counts3)\n",
        "print(X_train_tfidf3.shape)\n",
        "DF_TF_IDF3=pd.DataFrame(X_train_tfidf3.toarray())\n",
        "print(DF_TF_IDF3)\n",
        "export_csv= DF_TF_IDF3.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-TokenizedStemmed_3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 364)\n",
            "      0    1    2         3    4    5    6    ...  357  358  359  360  361  362  363\n",
            "0     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1     0.0  0.0  0.0  0.275669  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4     0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "...   ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2066  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2067  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2068  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2069  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 364 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTUPMS3M25bs",
        "colab_type": "code",
        "outputId": "1142aafd-3ea7-4b03-f203-34eac5d08354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#Add ID column\n",
        "print(CustInfoData.shape)\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "print(X_train.shape)\n",
        "DF_TF_IDF1 = pd.concat([newTextData1['ID'], DF_TF_IDF1], axis = 1)\n",
        "DF_TF_IDF1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 17)\n",
            "(2070, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "      <th>334</th>\n",
              "      <th>335</th>\n",
              "      <th>336</th>\n",
              "      <th>337</th>\n",
              "      <th>338</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "      <th>349</th>\n",
              "      <th>350</th>\n",
              "      <th>351</th>\n",
              "      <th>352</th>\n",
              "      <th>353</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.388928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.480064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.348322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 355 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID    0    1    2    3        4  ...  348  349  350  351  352  353\n",
              "0  1309  0.0  0.0  0.0  0.0  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  3556  0.0  0.0  0.0  0.0  0.27568  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  2230  0.0  0.0  0.0  0.0  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  2312  0.0  0.0  0.0  0.0  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  3327  0.0  0.0  0.0  0.0  0.00000  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 355 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB9xBihX8MDK",
        "colab_type": "code",
        "outputId": "9485af9f-f8ff-4218-9d43-2b867253306f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "#Merge Files\n",
        "#combined=pd.concat([X_train, DF_TF_IDF_SelectedFeatures], axis=1)\n",
        "combined = X_train.join(DF_TF_IDF1.set_index('ID'), on = 'ID')\n",
        "print(combined.shape)\n",
        "print(combined)\n",
        "export_csv= combined.to_csv(r'/gdrive/My Drive/Assignment 5/Combined-Cust+TFIDF.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2070, 370)\n",
            "        ID Sex Status  Children  Est_Income  ...  349  350  351  352  353\n",
            "0        1   F      S         1    38000.00  ...  0.0  0.0  0.0  0.0  0.0\n",
            "1        6   M      M         2    29616.00  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2        8   M      M         0    19732.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "3       11   M      S         2       96.33  ...  0.0  0.0  0.0  0.0  0.0\n",
            "4       14   F      M         2    52004.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "...    ...  ..    ...       ...         ...  ...  ...  ...  ...  ...  ...\n",
            "2065  3821   F      S         0    78851.30  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2066  3822   F      S         1    17540.70  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2067  3823   F      M         0    83891.90  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2068  3824   F      M         2    28220.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2069  3825   F      S         0    28589.10  ...  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 370 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbnKU9Jp-Xdl",
        "colab_type": "code",
        "outputId": "8a11f6f1-edc0-46ab-feec-36d69f5799f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Do one Hot encoding for categorical features\n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
        "print(X_cat)\n",
        "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
        "print(combined_one_hot.shape)\n",
        "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/Assignment 5/combined_one_hot.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
            "(2070, 378)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBj6vcE0Bvls",
        "colab_type": "code",
        "outputId": "d5424e47-bec7-40cc-b12a-f627bd989d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#splitting the traindata before proceeding for feature selection\n",
        "X_trainf, X_test, y_trainf, y_test = train_test_split(combined_one_hot, y_train, test_size = 0.2, random_state = 42)\n",
        "X_trainf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1656, 378)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2owIUD6_eYO",
        "colab_type": "code",
        "outputId": "85e5d4c4-6676-41c7-cd83-59839c4e883b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "#Feature selection\n",
        "new_DF_TF_IDF1 = SelectKBest(score_func=chi2, k=50).fit(X_trainf,y_trainf)\n",
        "\n",
        "new_X_trainf =  pd.DataFrame(new_DF_TF_IDF1.transform(X_trainf))\n",
        "print(new_X_trainf.head())\n",
        "#filering X_test also for prediction\n",
        "new_X_test = pd.DataFrame(new_DF_TF_IDF1.transform(X_test))\n",
        "\n",
        "\n",
        "DF_TF_IDF_Selected1= pd.DataFrame(new_X_trainf)\n",
        "print(DF_TF_IDF_Selected1)\n",
        "\n",
        "export_csv= DF_TF_IDF_Selected1.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-Selected Features1.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0    1         2       3      4    5   ...   44   45   46   47   48   49\n",
            "0  1517.0  0.0  95448.60   29.46  24.24  0.0  ...  0.0  1.0  1.0  0.0  0.0  0.0\n",
            "1  1892.0  0.0  17138.20  104.69  20.01  0.0  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2   339.0  0.0  92564.10   74.86  23.17  0.0  ...  1.0  0.0  0.0  1.0  1.0  0.0\n",
            "3  2236.0  0.0  43000.00   65.79  42.00  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
            "4   996.0  0.0   2031.61  109.04  21.64  0.0  ...  1.0  0.0  1.0  0.0  0.0  0.0\n",
            "\n",
            "[5 rows x 50 columns]\n",
            "          0    1         2       3      4    5   ...   44   45   46   47   48   49\n",
            "0     1517.0  0.0  95448.60   29.46  24.24  0.0  ...  0.0  1.0  1.0  0.0  0.0  0.0\n",
            "1     1892.0  0.0  17138.20  104.69  20.01  0.0  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2      339.0  0.0  92564.10   74.86  23.17  0.0  ...  1.0  0.0  0.0  1.0  1.0  0.0\n",
            "3     2236.0  0.0  43000.00   65.79  42.00  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
            "4      996.0  0.0   2031.61  109.04  21.64  0.0  ...  1.0  0.0  1.0  0.0  0.0  0.0\n",
            "...      ...  ...       ...     ...    ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1651  2993.0  2.0  38215.90    0.97   0.00  0.0  ...  1.0  0.0  1.0  0.0  1.0  0.0\n",
            "1652  1996.0  2.0  41876.60  139.44   6.78  0.0  ...  1.0  0.0  1.0  0.0  0.0  0.0\n",
            "1653  2042.0  0.0  95786.80  108.79  21.33  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
            "1654  2359.0  1.0  13091.60   43.06  22.79  0.0  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "1655  1533.0  0.0  90478.60  154.49  18.02  0.0  ...  0.0  1.0  0.0  1.0  0.0  0.0\n",
            "\n",
            "[1656 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvRMB-3w_vUZ",
        "colab_type": "code",
        "outputId": "ce59a487-3518-4c04-f40e-8c0f52c13f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "#Feature selection\n",
        "new_DF_TF_IDF2 = SelectKBest(score_func=chi2, k=30).fit(X_trainf,y_trainf)\n",
        "\n",
        "new_X_trainf2 =  pd.DataFrame(new_DF_TF_IDF2.transform(X_trainf))\n",
        "print(new_X_trainf2.head())\n",
        "#filering X_test also for prediction\n",
        "new_X_test2 = pd.DataFrame(new_DF_TF_IDF2.transform(X_test))\n",
        "\n",
        "\n",
        "DF_TF_IDF_Selected2= pd.DataFrame(new_X_trainf2)\n",
        "print(DF_TF_IDF_Selected2)\n",
        "\n",
        "export_csv= DF_TF_IDF_Selected2.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-Selected Features2.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0    1         2       3      4    5   ...   24        25   26   27   28   29\n",
            "0  1517.0  0.0  95448.60   29.46  24.24  0.0  ...  0.0  0.348322  1.0  1.0  0.0  0.0\n",
            "1  1892.0  0.0  17138.20  104.69  20.01  0.0  ...  0.0  0.000000  0.0  0.0  1.0  0.0\n",
            "2   339.0  0.0  92564.10   74.86  23.17  0.0  ...  0.0  0.000000  0.0  0.0  1.0  1.0\n",
            "3  2236.0  0.0  43000.00   65.79  42.00  0.0  ...  0.0  0.000000  0.0  0.0  1.0  0.0\n",
            "4   996.0  0.0   2031.61  109.04  21.64  0.0  ...  0.0  0.000000  0.0  1.0  0.0  0.0\n",
            "\n",
            "[5 rows x 30 columns]\n",
            "          0    1         2       3      4   ...        25   26   27   28   29\n",
            "0     1517.0  0.0  95448.60   29.46  24.24  ...  0.348322  1.0  1.0  0.0  0.0\n",
            "1     1892.0  0.0  17138.20  104.69  20.01  ...  0.000000  0.0  0.0  1.0  0.0\n",
            "2      339.0  0.0  92564.10   74.86  23.17  ...  0.000000  0.0  0.0  1.0  1.0\n",
            "3     2236.0  0.0  43000.00   65.79  42.00  ...  0.000000  0.0  0.0  1.0  0.0\n",
            "4      996.0  0.0   2031.61  109.04  21.64  ...  0.000000  0.0  1.0  0.0  0.0\n",
            "...      ...  ...       ...     ...    ...  ...       ...  ...  ...  ...  ...\n",
            "1651  2993.0  2.0  38215.90    0.97   0.00  ...  0.000000  0.0  1.0  0.0  1.0\n",
            "1652  1996.0  2.0  41876.60  139.44   6.78  ...  0.000000  0.0  1.0  0.0  0.0\n",
            "1653  2042.0  0.0  95786.80  108.79  21.33  ...  0.000000  0.0  0.0  1.0  0.0\n",
            "1654  2359.0  1.0  13091.60   43.06  22.79  ...  0.348322  1.0  1.0  0.0  0.0\n",
            "1655  1533.0  0.0  90478.60  154.49  18.02  ...  0.000000  1.0  0.0  1.0  0.0\n",
            "\n",
            "[1656 rows x 30 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2gb1XqjAI6P",
        "colab_type": "code",
        "outputId": "0c2389dc-4c98-4242-9361-d7661a71506c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "#Feature selection\n",
        "new_DF_TF_IDF3 = SelectKBest(score_func=chi2, k=90).fit(X_trainf,y_trainf)\n",
        "\n",
        "new_X_trainf3 =  pd.DataFrame(new_DF_TF_IDF3.transform(X_trainf))\n",
        "print(new_X_trainf3.head())\n",
        "#filering X_test also for prediction\n",
        "new_X_test3 = pd.DataFrame(new_DF_TF_IDF3.transform(X_test))\n",
        "\n",
        "\n",
        "DF_TF_IDF_Selected3= pd.DataFrame(new_X_trainf3)\n",
        "print(DF_TF_IDF_Selected3)\n",
        "\n",
        "export_csv= DF_TF_IDF_Selected3.to_csv(r'/gdrive/My Drive/Assignment 5/TFIDF_counts-Selected Features3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0    1         2       3          4   ...   85   86   87   88   89\n",
            "0  1517.0  0.0  95448.60   29.46  53.680000  ...  1.0  0.0  0.0  0.0  0.0\n",
            "1  1892.0  0.0  17138.20  104.69  63.786667  ...  0.0  1.0  0.0  1.0  1.0\n",
            "2   339.0  0.0  92564.10   74.86  49.133333  ...  0.0  1.0  1.0  0.0  0.0\n",
            "3  2236.0  0.0  43000.00   65.79  21.000000  ...  0.0  1.0  0.0  1.0  0.0\n",
            "4   996.0  0.0   2031.61  109.04  20.300000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "\n",
            "[5 rows x 90 columns]\n",
            "          0    1         2       3          4   ...   85   86   87   88   89\n",
            "0     1517.0  0.0  95448.60   29.46  53.680000  ...  1.0  0.0  0.0  0.0  0.0\n",
            "1     1892.0  0.0  17138.20  104.69  63.786667  ...  0.0  1.0  0.0  1.0  1.0\n",
            "2      339.0  0.0  92564.10   74.86  49.133333  ...  0.0  1.0  1.0  0.0  0.0\n",
            "3     2236.0  0.0  43000.00   65.79  21.000000  ...  0.0  1.0  0.0  1.0  0.0\n",
            "4      996.0  0.0   2031.61  109.04  20.300000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "...      ...  ...       ...     ...        ...  ...  ...  ...  ...  ...  ...\n",
            "1651  2993.0  2.0  38215.90    0.97  30.886667  ...  1.0  0.0  1.0  0.0  0.0\n",
            "1652  1996.0  2.0  41876.60  139.44  44.093333  ...  1.0  0.0  0.0  1.0  0.0\n",
            "1653  2042.0  0.0  95786.80  108.79  52.000000  ...  0.0  1.0  0.0  1.0  0.0\n",
            "1654  2359.0  1.0  13091.60   43.06  59.126667  ...  1.0  0.0  0.0  1.0  1.0\n",
            "1655  1533.0  0.0  90478.60  154.49  54.553333  ...  0.0  1.0  0.0  0.0  0.0\n",
            "\n",
            "[1656 rows x 90 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQbC4CHKDNcz",
        "colab_type": "code",
        "outputId": "b0e8cecc-f4b5-44c1-9790-2a6167e8f268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Decision Tree Classifier on combined data\n",
        "\n",
        "clf1=DecisionTreeClassifier()\n",
        "RF_Comb = clf1.fit(new_X_trainf,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf1.score(new_X_trainf, y_trainf)))\n",
        "rf_predictions = clf1.predict(new_X_test)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 1.000000\n",
            "Confusion Matrix:\n",
            "[[122  35]\n",
            " [ 46 211]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.73      0.78      0.75       157\n",
            "     Current       0.86      0.82      0.84       257\n",
            "\n",
            "    accuracy                           0.80       414\n",
            "   macro avg       0.79      0.80      0.79       414\n",
            "weighted avg       0.81      0.80      0.81       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhG-q4jRVgpI",
        "colab_type": "code",
        "outputId": "f12ef756-eff0-4339-bc60-8dbe5507c752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Decision Tree Classifier on combined data\n",
        "\n",
        "clf1=DecisionTreeClassifier()\n",
        "RF_Comb = clf1.fit(new_X_trainf2,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf1.score(new_X_trainf2, y_trainf)))\n",
        "rf_predictions = clf1.predict(new_X_test2)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 1.000000\n",
            "Confusion Matrix:\n",
            "[[124  33]\n",
            " [ 39 218]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.76      0.79      0.78       157\n",
            "     Current       0.87      0.85      0.86       257\n",
            "\n",
            "    accuracy                           0.83       414\n",
            "   macro avg       0.81      0.82      0.82       414\n",
            "weighted avg       0.83      0.83      0.83       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgAvLLYYWOKn",
        "colab_type": "code",
        "outputId": "409f9d80-27e3-499d-fe54-00a694ba8362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Decision Tree Classifier on combined data\n",
        "\n",
        "clf1=DecisionTreeClassifier()\n",
        "RF_Comb = clf1.fit(new_X_trainf3,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf1.score(new_X_trainf3, y_trainf)))\n",
        "rf_predictions = clf1.predict(new_X_test3)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 1.000000\n",
            "Confusion Matrix:\n",
            "[[129  28]\n",
            " [ 51 206]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.72      0.82      0.77       157\n",
            "     Current       0.88      0.80      0.84       257\n",
            "\n",
            "    accuracy                           0.81       414\n",
            "   macro avg       0.80      0.81      0.80       414\n",
            "weighted avg       0.82      0.81      0.81       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVOhURUZXtwT",
        "colab_type": "code",
        "outputId": "72a1be68-b846-414f-cf61-f2690b6fdd2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a MLP Classifier on combined data\n",
        "\n",
        "clf2=MLPClassifier()\n",
        "RF_Comb = clf2.fit(new_X_trainf,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf2.score(new_X_trainf, y_trainf)))\n",
        "rf_predictions = clf2.predict(new_X_test)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.440217\n",
            "Confusion Matrix:\n",
            "[[157   0]\n",
            " [235  22]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.40      1.00      0.57       157\n",
            "     Current       1.00      0.09      0.16       257\n",
            "\n",
            "    accuracy                           0.43       414\n",
            "   macro avg       0.70      0.54      0.36       414\n",
            "weighted avg       0.77      0.43      0.31       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFy8JfAjXTUy",
        "colab_type": "code",
        "outputId": "94892f39-51bd-4f2d-9e15-ec5b77952121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a MLP Classifier on combined data\n",
        "\n",
        "clf2=MLPClassifier()\n",
        "RF_Comb = clf2.fit(new_X_trainf2,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf2.score(new_X_trainf2, y_trainf)))\n",
        "rf_predictions = clf2.predict(new_X_test2)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.407005\n",
            "Confusion Matrix:\n",
            "[[157   0]\n",
            " [251   6]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.38      1.00      0.56       157\n",
            "     Current       1.00      0.02      0.05       257\n",
            "\n",
            "    accuracy                           0.39       414\n",
            "   macro avg       0.69      0.51      0.30       414\n",
            "weighted avg       0.77      0.39      0.24       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh8QBOODYEMX",
        "colab_type": "code",
        "outputId": "965ea21e-041e-418f-a4f9-2e683dfb581c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a MLP Classifier on combined data\n",
        "\n",
        "clf2=MLPClassifier()\n",
        "RF_Comb = clf2.fit(new_X_trainf3,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf2.score(new_X_trainf3, y_trainf)))\n",
        "rf_predictions = clf2.predict(new_X_test3)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.408816\n",
            "Confusion Matrix:\n",
            "[[157   0]\n",
            " [249   8]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.39      1.00      0.56       157\n",
            "     Current       1.00      0.03      0.06       257\n",
            "\n",
            "    accuracy                           0.40       414\n",
            "   macro avg       0.69      0.52      0.31       414\n",
            "weighted avg       0.77      0.40      0.25       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG56zUsEY03Y",
        "colab_type": "code",
        "outputId": "7b96f1d4-a012-4a07-81fc-b655fb05abf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Random Forest Classifier on combined data\n",
        "\n",
        "clf3=RandomForestClassifier()\n",
        "RF_Comb = clf3.fit(new_X_trainf,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf3.score(new_X_trainf, y_trainf)))\n",
        "rf_predictions = clf3.predict(new_X_test)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.985507\n",
            "Confusion Matrix:\n",
            "[[126  31]\n",
            " [ 33 224]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.79      0.80      0.80       157\n",
            "     Current       0.88      0.87      0.88       257\n",
            "\n",
            "    accuracy                           0.85       414\n",
            "   macro avg       0.84      0.84      0.84       414\n",
            "weighted avg       0.85      0.85      0.85       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uxLhKqYOHo",
        "colab_type": "code",
        "outputId": "a3606c07-37f0-4022-8c4a-986941148611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Random Forest Classifier on combined data\n",
        "\n",
        "clf3=RandomForestClassifier()\n",
        "RF_Comb = clf3.fit(new_X_trainf2,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf3.score(new_X_trainf2, y_trainf)))\n",
        "rf_predictions = clf3.predict(new_X_test2)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.983092\n",
            "Confusion Matrix:\n",
            "[[127  30]\n",
            " [ 29 228]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.81      0.81      0.81       157\n",
            "     Current       0.88      0.89      0.89       257\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.85      0.85       414\n",
            "weighted avg       0.86      0.86      0.86       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcYcVEIiY8In",
        "colab_type": "code",
        "outputId": "d94d37e9-be48-489c-d92e-808d9d6ec20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Construct a Random Forest Classifier on combined data\n",
        "\n",
        "clf3=RandomForestClassifier()\n",
        "RF_Comb = clf3.fit(new_X_trainf3,y_trainf)\n",
        "print(\"Accuracy score (training): {0:.6f}\".format(clf3.score(new_X_trainf3, y_trainf)))\n",
        "rf_predictions = clf3.predict(new_X_test3)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.986715\n",
            "Confusion Matrix:\n",
            "[[127  30]\n",
            " [ 34 223]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.79      0.81      0.80       157\n",
            "     Current       0.88      0.87      0.87       257\n",
            "\n",
            "    accuracy                           0.85       414\n",
            "   macro avg       0.84      0.84      0.84       414\n",
            "weighted avg       0.85      0.85      0.85       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW2C8XTxsCc4",
        "colab_type": "code",
        "outputId": "f622ba6c-4671-4f4a-b6c0-e3dac7b75f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build DT classifier to use in feature selection\n",
        "clfw1 = DecisionTreeClassifier()\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clfw1,\n",
        "           k_features=30,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_trainf, y_trainf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed:    5.6s finished\n",
            "\n",
            "[2019-12-08 23:02:04] Features: 1/30 -- score: 0.863503527981743[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:    7.1s finished\n",
            "\n",
            "[2019-12-08 23:02:11] Features: 2/30 -- score: 0.8737608936156601[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:    7.3s finished\n",
            "\n",
            "[2019-12-08 23:02:18] Features: 3/30 -- score: 0.8785984035013993[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:    7.4s finished\n",
            "\n",
            "[2019-12-08 23:02:25] Features: 4/30 -- score: 0.8792044641074599[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:    7.5s finished\n",
            "\n",
            "[2019-12-08 23:02:33] Features: 5/30 -- score: 0.8792062951062697[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:    7.6s finished\n",
            "\n",
            "[2019-12-08 23:02:41] Features: 6/30 -- score: 0.8792062951062697[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 372 out of 372 | elapsed:    7.7s finished\n",
            "\n",
            "[2019-12-08 23:02:48] Features: 7/30 -- score: 0.8792062951062697[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 371 out of 371 | elapsed:    7.8s finished\n",
            "\n",
            "[2019-12-08 23:02:56] Features: 8/30 -- score: 0.8792062951062697[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 370 out of 370 | elapsed:    7.7s finished\n",
            "\n",
            "[2019-12-08 23:03:04] Features: 9/30 -- score: 0.8798105247135204[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 369 out of 369 | elapsed:    7.9s finished\n",
            "\n",
            "[2019-12-08 23:03:12] Features: 10/30 -- score: 0.8804129343520746[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 368 out of 368 | elapsed:    7.9s finished\n",
            "\n",
            "[2019-12-08 23:03:20] Features: 11/30 -- score: 0.8804129343520746[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 367 out of 367 | elapsed:    7.9s finished\n",
            "\n",
            "[2019-12-08 23:03:28] Features: 12/30 -- score: 0.8804129343520746[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 366 out of 366 | elapsed:    7.8s finished\n",
            "\n",
            "[2019-12-08 23:03:35] Features: 13/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 365 out of 365 | elapsed:    8.0s finished\n",
            "\n",
            "[2019-12-08 23:03:43] Features: 14/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 364 out of 364 | elapsed:    8.0s finished\n",
            "\n",
            "[2019-12-08 23:03:51] Features: 15/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 363 out of 363 | elapsed:    8.1s finished\n",
            "\n",
            "[2019-12-08 23:04:00] Features: 16/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 362 out of 362 | elapsed:    8.1s finished\n",
            "\n",
            "[2019-12-08 23:04:08] Features: 17/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 361 out of 361 | elapsed:    8.1s finished\n",
            "\n",
            "[2019-12-08 23:04:16] Features: 18/30 -- score: 0.8810153439906289[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    8.3s finished\n",
            "\n",
            "[2019-12-08 23:04:24] Features: 19/30 -- score: 0.881617753629183[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 359 out of 359 | elapsed:    8.9s finished\n",
            "\n",
            "[2019-12-08 23:04:33] Features: 20/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 358 out of 358 | elapsed:    8.8s finished\n",
            "\n",
            "[2019-12-08 23:04:42] Features: 21/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 357 out of 357 | elapsed:    8.7s finished\n",
            "\n",
            "[2019-12-08 23:04:51] Features: 22/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 356 out of 356 | elapsed:    8.9s finished\n",
            "\n",
            "[2019-12-08 23:05:00] Features: 23/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 355 out of 355 | elapsed:    8.8s finished\n",
            "\n",
            "[2019-12-08 23:05:08] Features: 24/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 354 out of 354 | elapsed:    9.2s finished\n",
            "\n",
            "[2019-12-08 23:05:18] Features: 25/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 353 out of 353 | elapsed:    9.2s finished\n",
            "\n",
            "[2019-12-08 23:05:27] Features: 26/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:    9.3s finished\n",
            "\n",
            "[2019-12-08 23:05:36] Features: 27/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:    9.2s finished\n",
            "\n",
            "[2019-12-08 23:05:45] Features: 28/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:    9.3s finished\n",
            "\n",
            "[2019-12-08 23:05:55] Features: 29/30 -- score: 0.8822219832364337[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:    9.0s finished\n",
            "\n",
            "[2019-12-08 23:06:04] Features: 30/30 -- score: 0.8822219832364337"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSG9p6Fiw4B4",
        "colab_type": "code",
        "outputId": "ab56246f-26e8-479c-df33-fa208de33fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#copying selected features\n",
        "selected_features1 = list(sfs1.k_feature_names_)\n",
        "print(selected_features1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Usage', 0, 2, 5, 8, 13, 15, 16, 17, 24, 25, 37, 41, 48, 50, 60, 62, 66, 67, 106, 122, 132, 135, 158, 161, 192, 220, 315, 'Sex_F', 'LongDistanceBilltype_Standard']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKskbzesB8M",
        "colab_type": "code",
        "outputId": "5c439c84-f1e5-4cc9-bf01-42ed7450c830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#using the selected features for full model - default decision tree classifier\n",
        "clfw1 = DecisionTreeClassifier()\n",
        "clfw1.fit(X_trainf[selected_features1], y_trainf)\n",
        "y_pred = clfw1.predict(X_test[selected_features1])\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.77      0.85      0.81       157\n",
            "     Current       0.90      0.85      0.88       257\n",
            "\n",
            "    accuracy                           0.85       414\n",
            "   macro avg       0.84      0.85      0.84       414\n",
            "weighted avg       0.86      0.85      0.85       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7EyQFWN0Sct",
        "colab_type": "code",
        "outputId": "3d41a2bf-9784-46c3-b477-c58046d1caf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build RF classifier to use in feature selection\n",
        "clfw2 = RandomForestClassifier(n_estimators = 30, random_state = 42)\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs2 = sfs(clfw2,\n",
        "           k_features=30,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs2 = sfs2.fit(X_trainf, y_trainf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed:  1.2min finished\n",
            "\n",
            "[2019-12-09 00:40:58] Features: 1/30 -- score: 0.8604914908190852[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:  1.8min finished\n",
            "\n",
            "[2019-12-09 00:42:45] Features: 2/30 -- score: 0.8749821367314906[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:44:27] Features: 3/30 -- score: 0.884040142994389[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:46:09] Features: 4/30 -- score: 0.8870613130908694[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:47:50] Features: 5/30 -- score: 0.8888758218813182[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:49:30] Features: 6/30 -- score: 0.8894782425499856[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 372 out of 372 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:51:11] Features: 7/30 -- score: 0.891290931371738[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 371 out of 371 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:52:51] Features: 8/30 -- score: 0.891290931371738[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 370 out of 370 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:54:33] Features: 9/30 -- score: 0.8912927513404345[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 369 out of 369 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:56:14] Features: 10/30 -- score: 0.891290931371738[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 368 out of 368 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:57:55] Features: 11/30 -- score: 0.8918951609789888[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 367 out of 367 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 00:59:35] Features: 12/30 -- score: 0.8931036312236035[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 366 out of 366 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:01:17] Features: 13/30 -- score: 0.8924994016163528[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 365 out of 365 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:02:58] Features: 14/30 -- score: 0.8924994016163528[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 364 out of 364 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:04:39] Features: 15/30 -- score: 0.891898811946495[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 363 out of 363 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:06:22] Features: 16/30 -- score: 0.8924993905862395[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 362 out of 362 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:08:04] Features: 17/30 -- score: 0.8931036201934903[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 361 out of 361 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:09:45] Features: 18/30 -- score: 0.8931072711609966[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:11:27] Features: 19/30 -- score: 0.8925030415537458[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 359 out of 359 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:13:08] Features: 20/30 -- score: 0.8931072711609966[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 358 out of 358 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:14:49] Features: 21/30 -- score: 0.892501210554936[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 357 out of 357 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:16:30] Features: 22/30 -- score: 0.8925048615224425[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 356 out of 356 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:18:12] Features: 23/30 -- score: 0.8931054511923001[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 355 out of 355 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:19:53] Features: 24/30 -- score: 0.8918969699175718[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 354 out of 354 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:21:35] Features: 25/30 -- score: 0.8919006319151916[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 353 out of 353 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:23:16] Features: 26/30 -- score: 0.8919024518838882[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:24:58] Features: 27/30 -- score: 0.8925030415537458[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:26:40] Features: 28/30 -- score: 0.8931054511923001[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:28:20] Features: 29/30 -- score: 0.8931090911296933[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:  1.7min finished\n",
            "\n",
            "[2019-12-09 01:30:00] Features: 30/30 -- score: 0.8931036201934903"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQyXe16HUc_r",
        "colab_type": "code",
        "outputId": "13b287a2-0586-479e-b253-fa57b152c967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#copying selected features\n",
        "selected_features2 = list(sfs2.k_feature_names_)\n",
        "print(selected_features2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Age', 3, 4, 11, 33, 53, 58, 68, 70, 89, 92, 123, 128, 141, 144, 161, 163, 175, 201, 207, 220, 283, 286, 331, 333, 337, 347, 351, 'Sex_F', 'Sex_M']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnrdeOO3Ulut",
        "colab_type": "code",
        "outputId": "e3c3e937-1caf-4771-dfe1-599c9dd6b6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#using the selected features for full model - default Random Forest classifier\n",
        "clfw2 = RandomForestClassifier()\n",
        "clfw2.fit(X_trainf[selected_features2], y_trainf)\n",
        "y_pred = clfw2.predict(X_test[selected_features2])\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.83      0.87      0.85       157\n",
            "     Current       0.92      0.89      0.90       257\n",
            "\n",
            "    accuracy                           0.88       414\n",
            "   macro avg       0.87      0.88      0.88       414\n",
            "weighted avg       0.88      0.88      0.88       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bNElNsJVPAA",
        "colab_type": "code",
        "outputId": "86a0550b-8f91-4113-bff0-81ef073b6fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build Gradient Boosting Classifier to use in feature selection\n",
        "clfw3 = GradientBoostingClassifier()\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs3 = sfs(clfw3,\n",
        "           k_features=30,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs3 = sfs3.fit(X_trainf, y_trainf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed:  1.4min finished\n",
            "\n",
            "[2019-12-09 01:50:51] Features: 1/30 -- score: 0.786844516213715[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:  2.1min finished\n",
            "\n",
            "[2019-12-09 01:52:58] Features: 2/30 -- score: 0.8116088964481932[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:  2.3min finished\n",
            "\n",
            "[2019-12-09 01:55:17] Features: 3/30 -- score: 0.8484342202647447[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:  2.4min finished\n",
            "\n",
            "[2019-12-09 01:57:43] Features: 4/30 -- score: 0.8780106308232105[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:  2.6min finished\n",
            "\n",
            "[2019-12-09 02:00:18] Features: 5/30 -- score: 0.8852614302306728[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:  2.8min finished\n",
            "\n",
            "[2019-12-09 02:03:05] Features: 6/30 -- score: 0.8870759610813483[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 372 out of 372 | elapsed:  2.8min finished\n",
            "\n",
            "[2019-12-09 02:05:55] Features: 7/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 371 out of 371 | elapsed:  2.9min finished\n",
            "\n",
            "[2019-12-09 02:08:48] Features: 8/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 370 out of 370 | elapsed:  2.9min finished\n",
            "\n",
            "[2019-12-09 02:11:45] Features: 9/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 369 out of 369 | elapsed:  3.0min finished\n",
            "\n",
            "[2019-12-09 02:14:44] Features: 10/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 368 out of 368 | elapsed:  3.0min finished\n",
            "\n",
            "[2019-12-09 02:17:47] Features: 11/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 367 out of 367 | elapsed:  3.1min finished\n",
            "\n",
            "[2019-12-09 02:20:52] Features: 12/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 366 out of 366 | elapsed:  3.1min finished\n",
            "\n",
            "[2019-12-09 02:23:58] Features: 13/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 365 out of 365 | elapsed:  3.1min finished\n",
            "\n",
            "[2019-12-09 02:27:06] Features: 14/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 364 out of 364 | elapsed:  3.2min finished\n",
            "\n",
            "[2019-12-09 02:30:17] Features: 15/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 363 out of 363 | elapsed:  3.2min finished\n",
            "\n",
            "[2019-12-09 02:33:31] Features: 16/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 362 out of 362 | elapsed:  3.3min finished\n",
            "\n",
            "[2019-12-09 02:36:47] Features: 17/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 361 out of 361 | elapsed:  3.3min finished\n",
            "\n",
            "[2019-12-09 02:40:06] Features: 18/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  3.4min finished\n",
            "\n",
            "[2019-12-09 02:43:28] Features: 19/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 359 out of 359 | elapsed:  3.4min finished\n",
            "\n",
            "[2019-12-09 02:46:52] Features: 20/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 358 out of 358 | elapsed:  3.4min finished\n",
            "\n",
            "[2019-12-09 02:50:16] Features: 21/30 -- score: 0.8882807803584566[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 357 out of 357 | elapsed:  3.4min finished\n",
            "\n",
            "[2019-12-09 02:53:42] Features: 22/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 356 out of 356 | elapsed:  3.5min finished\n",
            "\n",
            "[2019-12-09 02:57:10] Features: 23/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 355 out of 355 | elapsed:  3.5min finished\n",
            "\n",
            "[2019-12-09 03:00:39] Features: 24/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 354 out of 354 | elapsed:  3.5min finished\n",
            "\n",
            "[2019-12-09 03:04:10] Features: 25/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 353 out of 353 | elapsed:  3.6min finished\n",
            "\n",
            "[2019-12-09 03:07:45] Features: 26/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:  3.6min finished\n",
            "\n",
            "[2019-12-09 03:11:21] Features: 27/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:  3.6min finished\n",
            "\n",
            "[2019-12-09 03:14:59] Features: 28/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:  3.7min finished\n",
            "\n",
            "[2019-12-09 03:18:41] Features: 29/30 -- score: 0.8894874196042615[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:  3.7min finished\n",
            "\n",
            "[2019-12-09 03:22:25] Features: 30/30 -- score: 0.8900898292428158"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mminsr5VV9tC",
        "colab_type": "code",
        "outputId": "62bcaa6f-607e-41d8-97d4-bb9d59035804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#copying selected features\n",
        "selected_features3 = list(sfs3.k_feature_names_)\n",
        "print(selected_features3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Est_Income', 'Age', 'LongDistance', 'Local', 0, 3, 5, 10, 11, 13, 15, 16, 26, 31, 34, 35, 41, 44, 45, 46, 56, 57, 60, 61, 72, 94, 193, 299, 303, 'Sex_F']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBDx_yLXz4Tk",
        "colab_type": "code",
        "outputId": "3a3b92a8-fb6d-4767-cb6f-f862c8997cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#using the selected features for full model - default Gradient Boosting classifier\n",
        "clfw3.fit(X_trainf[selected_features3], y_trainf)\n",
        "y_pred = clfw3.predict(X_test[selected_features3])\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.82      0.70      0.76       157\n",
            "     Current       0.83      0.91      0.87       257\n",
            "\n",
            "    accuracy                           0.83       414\n",
            "   macro avg       0.83      0.80      0.81       414\n",
            "weighted avg       0.83      0.83      0.83       414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}